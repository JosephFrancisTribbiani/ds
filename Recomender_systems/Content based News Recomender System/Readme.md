Based on [article]("https://www.kaggle.com/code/achintyatripathi/content-based-news-recomender-system/notebook")

Кратко о подходе: есть список новостей (текстов). Необходимо на основании прочитанной пользователем новости рекомендовать к прочтению некоторе количество других новостей, похожих на прочтенную. Тексты новостей из обучающей выборки кодируются с помощью TF-IDF. Далее между всеми парами считается косинусова близость. На основании значения косинусовой близости других новостей с прочтенной они ранжируются и выдается ТОП полученного списка (наиболее близкие).

# TF-IDF

$$
\text{TF-IDF(t, d, D)} = \text{TF(t, d)} \times \text{IDF(t, D)} \\

\text{TF(t, d)} = \frac{|t|_d}{|d|} \\

\text{IDF(t, D)} = \log{\frac{|D|}{|\{ d_i \in D | t \in d_i \}|}}
$$

где
- $t$ - текущий токен
- $|t|_d$ - количество токенов $t$ в документе $d$
- $|d|$ - количество слов в документе $d$
- $d$ - текущий документ
- $D$ - множество всех документов
- $|D|$ - количество документов во множестве $D$
- $|\{ d_i \in D | t \in d_i \}|$ - число документов из $D$, в которых встречается токен $t$
- $\text{TF(t, d)}$ - term frequency, показывает частоту токена $t$ в документе $d$. Определяется как отношение числа вхождений текущего токена $t$ к общему числу токенов в документе $d$.
- $\text{IDF(t, D)}$ -  (inverse document frequency — обратная частота документа) — инверсия частоты, с которой некоторое слово встречается в документах коллекции.

# Cosine similarity

Диапазон значений [0, 1]

$$
\text{sim}(A, B) = \cos{\theta} = \frac{A \times B}{||A|| \cdot ||B||}
$$

- $A \times B$ - векторное произведение двух векторов
$$A \times B = \sum_{i=1}^{n}{A_i B_i}$$
- $||A||$, $||B||$ - длины векторов $A$ и $B$ соответственно