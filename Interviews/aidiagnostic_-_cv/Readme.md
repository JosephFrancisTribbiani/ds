## Описание

В рамках тестового задания необходимо решить задачу сегментации плеврального выпота на снимках легких человека. Подробное описание тестового задания [здесь](./Description.md).

## Решение

### Анализ данных для обучения

Предоставленные данные - это 10-ть наборов медицинских снимков легких с номерами {1, 2, 5, 8, 13, 16, 18, 24, 26, 28} 10-ти пациентов размера 512 х 512. Каждый набор включает некоторое количество таких снимков и каждый снимок соответствует "срезу" туловища пациента. Для каждого набора имеется трехмерная маска со значениями {0, 1}, где 1 соответствует плевральному выпоту.

Информация по расположению файлов была агрегирована в [metadata.json](./data/metadata.json).

Ниже представлен пример снимков {0, 5, 10, 15, 20, 25, 30, 35, 40, 45} для пациента 26. Синим цветом обозначен ground truth для соответствующего среза.

<img src="./images/example_26.jpg"></img>

Диаграмма распределения плеврального выпота вдоль размерности 0 (вдоль координаты "Z") для каждого набора снимков (обозначено цветом):

<img src="./images/z_distrib.jpg"></img>

Диаграмма распределения плеврального выпота вдоль размерностей 1 и 2 (вдоль координат "Y" и "X" соответственно) для каждого набора снимков (обозначено цветом):

<img src="./images/xy_distrib.jpg"></img>

Как видно из диаграмм, класс 1, соответствующий плевральному выпоту, находится преимущественно в диапазоне [0, 85] для размерности 0 ("Z"), [250, 400] для размерности 1 ("Y") и [100, 400] для размерности 2 ("X").

### Выбор подхода для решения поставленной задачи

Для решения поставленной задачи решено использовать модель `Unet++` с `resnet34` в качестве энкодера. Данная модель, хоть и не является SOTA для такого рода задач, но вполне достаточна для демонстрации умений в рамках тестового задания и была выбрана с целью минимизации времени обучения. Для использования других архитектур достаточно указать необходимую модель в [конфигурационном файле](./config.yaml).

Модель обучалась только на 2-х мерных срезах вдоль размерности 0 (ось "Z").

### Аугментация данных

В силу малого объема данных для обучения модели необходима аугментация данных. Для аугментации данных использовались следующие шаги:
1. Вращение 3-х мерного тезора размера N х 512 х 512 относительно осей "Y" и "X" (размерности 1 и 2 соответственно), где N - количество срезов вдоль размерности 0 (ось "Z") для набора снимков пациента. Вращение осуществлялось случайным образом относительно центра среза, к которому применялась аугментация.
2. После вращения 3-х мерного тезора размера N х 512 х 512 относительно осей "Y" и "X" двухмерный срез размера 512 х 512, для которого производилась аугментация, отделялся от остальных срезов. Дальнейшие шаги по аугментации производились только с этим 2-х мерным срезом.
3. Вращение 2-х мерного среза на случайный угол из промежутка [-15, 15].
4. Случайная обрезка изображения. Размер итогового изображения 408 х 408.
5. Отражение относительно вертикальной оси.

Шаги {1, 3, 4, 5} применялись с вероятностями `p_3drot`, `p_2drot`, `p_rcrop`, `p_hflip` соответственно. Значения данных вероятностей указываются в [конфигурационном файле](./config.yaml), или если не указано, то используется `default` значение (см. DataSetConfig в файле [utils.py](./aidiagnostic/utils.py)). При решении данной задачи для уменьшения времени обучения `p_3drot` было выставлено равным 0.

Далее размер среза уменьшался до размера 224 х 224 и нормализовался. Также дублировался единственный канал до 3-х, с целью использования предобученной на `imagenet` модели. Итоговое количество каналов также может быть указано в [конфигурационном файле](./config.yaml). Описанные шаги аугментации можно посмотреть в методе `transform` класса `AiDiagnosticDataset` в файле [dataset.py](./aidiagnostic/dataset.py).

### Запуск процесса обучения

Для удобства обучения модели был написан [скрипт](./aidiagnostic_go.py). Для запуска обучения модели необходимо выполнить команду:

```bash
python aidiagnostic_go.py
```

Ниже представлены опции:

```bash
--device                указывается на чем обучать модель, "cuda" (по умолчанию) или "cpu"
--dice                  если указано, то рассчитывать dice loss
--bce                   если указано, то рассчитывать bce loss
--lr                    начальная скорость обучения, по умолчанию 3e-3
--patience              кличество эпох, после которых если не произошло суммарное уменьшение функции потерь, то производится
                        уменьшение скорости обучение, по умолчанию 10
--factor                коэфициент, на который домножается значение скорости обучения, по умолчанию 0.05
--writer-path           путь, у 
--model-loc
--config-loc
-ts, --train-size
-e, --epochs
```

### Результаты